{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Use the search_experiments function to get a list of available experiments\n",
    "experiments = client.search_experiments()\n",
    "print(len(experiments))\n",
    "\n",
    "# Display the list of available experiments\n",
    "for experiment in experiments:\n",
    "    print(f\"Experiment Name: {experiment.name}, Experiment ID: {experiment.experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "df = load_data('Data/clean_diamonds_final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert byte literals to regular strings for specific columns\n",
    "\"\"\"byte_literal_columns = ['cut', 'color', 'clarity']\n",
    "for column in byte_literal_columns:\n",
    "    df[column] = df[column].str.strip(\"b'\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "# print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any duplicate rows\n",
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows with missing values\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out unique values in each categorical column\n",
    "print(\"Unique values in 'cut' column:\", df['cut'].unique())\n",
    "print(\"Unique values in 'color' column:\", df['color'].unique())\n",
    "print(\"Unique values in 'clarity' column:\", df['clarity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "# df.to_csv('data/clean_diamonds_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below bar charts will show the number of diamonds in each category, which will help us understand why these variables are considered categorical:\n",
    "\n",
    "cut: The quality of the cut is a categorical variable because it describes the cut quality of the diamond in ordered categories such as 'Ideal', 'Premium', 'Good', etc.\n",
    "\n",
    "color: The color of the diamond is a categorical variable because it is rated on a scale from D (best) to J (worst), representing discrete groups.\n",
    "\n",
    "clarity: The clarity of the diamond is a categorical variable because it describes the level of flaws in the diamond using categories like 'SI1', 'VS1', 'VVS2', etc.\n",
    "\n",
    "\n",
    "These visualizations will show that each of these variables contains a limited number of distinct categories, which is a characteristic of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Assuming 'df' is your dataframe and it has been loaded correctly from the provided CSV file\n",
    "\n",
    "# Interactive bar plot for 'cut'\n",
    "cut_counts = df['cut'].value_counts().reset_index()\n",
    "cut_counts.columns = ['cut', 'count']  # Rename the columns appropriately\n",
    "fig = px.bar(cut_counts, x='cut', y='count')\n",
    "fig.update_layout(title_text='Distribution of Cut Quality', xaxis_title='Cut', yaxis_title='Frequency')\n",
    "fig.show()\n",
    "\n",
    "# Interactive bar plot for 'color'\n",
    "color_counts = df['color'].value_counts().reset_index()\n",
    "color_counts.columns = ['color', 'count']  # Rename the columns appropriately\n",
    "fig = px.bar(color_counts, x='color', y='count')\n",
    "fig.update_layout(title_text='Distribution of Diamond Color', xaxis_title='Color', yaxis_title='Frequency')\n",
    "fig.show()\n",
    "\n",
    "# Interactive bar plot for 'clarity'\n",
    "clarity_counts = df['clarity'].value_counts().reset_index()\n",
    "clarity_counts.columns = ['clarity', 'count']  # Rename the columns appropriately\n",
    "fig = px.bar(clarity_counts, x='clarity', y='count')\n",
    "fig.update_layout(title_text='Distribution of Diamond Clarity', xaxis_title='Clarity', yaxis_title='Frequency')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLS = [\"cut\", \"color\", \"clarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def encode_cols(df: pd.DataFrame, categorical_cols: List[str] = None) -> pd.DataFrame:\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = [\"cut\", \"color\", \"clarity\"]\n",
    "        \n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda x: x.astype(str).str.lower())\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_x_y(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: List[str] = None,\n",
    "    dv: DictVectorizer = None,\n",
    "    with_target: bool = True,\n",
    ") -> dict:\n",
    "    if categorical_cols is None:\n",
    "         categorical_cols = [\"cut\", \"color\", \"clarity\"]\n",
    "    dicts = df[[*categorical_cols]].to_dict(orient=\"records\")\n",
    "\n",
    "    y = None\n",
    "    if with_target:\n",
    "        if dv is None:\n",
    "            dv = DictVectorizer()\n",
    "            dv.fit(dicts)\n",
    "        y = df[\"price\"].values\n",
    "\n",
    "    x = dv.transform(dicts)\n",
    "    return x, y, dv\n",
    "\n",
    "# save the preprocessor into saved_pkl folder\n",
    "import pickle\n",
    "def save_picked(path: str, file):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# try all steps\n",
    "df = load_data('data/clean_diamonds_final.csv')\n",
    "df.to_csv(\"data/clean_diamonds_final.csv\", index=False)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.to_csv(\"data/train-set.csv\")\n",
    "test_df.to_csv(\"data/test-set.csv\")\n",
    "train_df = encode_cols(train_df)\n",
    "test_df = encode_cols(test_df)\n",
    "X_train, y_train, dv = extract_x_y(train_df)\n",
    "X_test, y_test, _ = extract_x_y(test_df, dv=dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBRegressor  \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from typing import List\n",
    "\n",
    "# Set the experiment name\n",
    "mlflow.set_experiment(\"diamonds_price_predictor\")\n",
    "\n",
    "# Check if there's an active run, and end it if necessary\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Start a run\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # Set tags for the run\n",
    "    mlflow.set_tag(\"experiment_id\", run_id)\n",
    "\n",
    "    # Load data - assuming you have functions to load your data\n",
    "    train_df = load_data(\"data/train-set.csv\")\n",
    "    test_df = load_data(\"data/test-set.csv\")\n",
    "\n",
    "    # Preprocess the text data\n",
    "    train_text = train_df[['cut', 'color', 'clarity']].apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "    test_text = test_df[['cut', 'color', 'clarity']].apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "\n",
    "    # Vectorize the text data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train_text)\n",
    "    X_test = vectorizer.transform(test_text)\n",
    "\n",
    "    # Check the number of features\n",
    "    # print(f'Number of features in X_train: {X_train.shape[1]}')\n",
    "    # print(f'Number of features in X_test: {X_test.shape[1]}')\n",
    "\n",
    "    y_train = train_df['price']\n",
    "    y_test = test_df['price']\n",
    "\n",
    "    # Convert data into ndarrays\n",
    "    train_x = X_train.toarray()\n",
    "    test_x = X_test.toarray()\n",
    "\n",
    "    # Convert y_train and y_test to ndarrays\n",
    "    train_y = y_train.values\n",
    "    test_y = y_test.values\n",
    "\n",
    "\n",
    "    # Train a regression model - changed to XGBoost (XGBRegressor)\n",
    "    model = XGBRegressor()  # Instantiate XGBRegressor\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "    mlflow.log_metric(\"train_mae\", train_mae)\n",
    "    mlflow.log_metric(\"train_mse\", train_mse)\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "\n",
    "    print(\"Train MAE:\", train_mae)\n",
    "    print(\"Train MSE:\", train_mse)\n",
    "    print(\"Train R2:\", train_r2)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    mlflow.log_metric(\"test_mae\", test_mae)\n",
    "    mlflow.log_metric(\"test_mse\", test_mse)\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "\n",
    "    print(\"Test MAE:\", test_mae)\n",
    "    print(\"Test MSE:\", test_mse)\n",
    "    print(\"Test R2:\", test_r2)\n",
    "\n",
    "    # Log the model - XGBoost model\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Register the model in MLflow Model Registry\n",
    "    model_name = \"diamond_price_predictor_xgb01\"  # Update model name accordingly\n",
    "    model_description = \"XGBoost Diamond Price Predictor\"  # Update model description accordingly\n",
    "    mlflow.register_model(\"runs:/{}/model\".format(run_id), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Initialize MLflow tracking client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Set the correct model type and experiment path\n",
    "model_type = \"xgboost\"  # Update model type\n",
    "mlflow_experiment_path = 'diamond_price_predictor_xgb'  # Adjusted experiment path for XGBoost model\n",
    "\n",
    "# Specify the version of the model to be transitioned\n",
    "production_version = 1\n",
    "\n",
    "# Transition the specified model version to the \"Production\" stage\n",
    "client.transition_model_version_stage(name=mlflow_experiment_path, version=production_version, stage=\"Production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui --host 0.0.0.0 --port 5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(file, path):\n",
    "    \"\"\"\n",
    "    Save the file using pickle.\n",
    "    \n",
    "    Parameters:\n",
    "        file: Any - The object to be saved.\n",
    "        path: str - The path to save the file.\n",
    "    \"\"\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(file, f)\n",
    "\n",
    "# Example usage:\n",
    "save_pickle(model, \"/Users/mohammedzaidsyed/Desktop/Diamond/MLOPS_Diamond/Model_savedpkl/Model_v/model.pkl\")\n",
    "save_pickle(dv, \"/Users/mohammedzaidsyed/Desktop/Diamond/MLOPS_Diamond/Model_savedpkl/dv_v/dv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config import PATH_TO_MODEL, PATH_TO_PREPROCESSOR\n",
    "# Load production model\n",
    "model_uri = f\"models:/{mlflow_experiment_path}/production\"\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "save_picked(\"/Users/mohammedzaidsyed/Desktop/Diamond/MLOPS_Diamond/Model_savedpkl/Model_v/model.pkl\", model)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        file = pickle.load(f)\n",
    "    return file\n",
    "\n",
    "dv = load_pickle(\"/Users/mohammedzaidsyed/Desktop/Diamond/MLOPS_Diamond/Model_savedpkl/dv_v/dv.pkl\")\n",
    "model = load_pickle(\"/Users/mohammedzaidsyed/Desktop/Diamond/MLOPS_Diamond/Model_savedpkl/Model_v/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow server --host 127.0.0.1 --port 8080"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
